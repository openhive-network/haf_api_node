# Appender definition JSON. Obligatory attributes:
# "appender" - name of appender
# "stream" - target stream, mutually exclusive with "file"
# "file" - target filename (including path), mutually exclusive with "stream"
# Optional attributes:
# "time_format" - see time_format enum values (default: "iso_8601_seconds")
# Optional attributes (applicable to file appender only):
# "delta_times" - whether times should be printed as deltas since previous message (default: false)
# "flush" - whether each log write should end with flush (default: true)
# "truncate" - whether to truncate the log file at startup (default: true)
# "rotate" - whether the log files should be rotated (default: true)
# "rotation_interval" - seconds between file rotation (default: 3600)
# "rotation_limit" - seconds before rotated file is removed (default: 86400)
log-appender = {"appender":"stderr","stream":"std_error","time_format":"iso_8601_microseconds"} {"appender":"p2p","file":"logs/hived/p2p/p2p.log","truncate":false,"time_format":"iso_8601_milliseconds", "rotation_interval": 86400, "rotation_limit": 2592000} {"appender": "default", "file": "logs/hived/default/default.log","truncate":false, "time_format": "iso_8601_milliseconds", "rotation_interval": 86400, "rotation_limit": 2592000}

# log-console-appender = 

# log-file-appender = 

# Logger definition JSON:
# "name" - name of logger
# "level" - level of reporting, see log_level enum values
# "appenders" - list of designated appenders
log-logger = {"name":"default","level":"info","appenders":["stderr", "default"]} {"name":"user","level":"debug","appenders":["stderr", "default"]} {"name":"p2p","level":"warn","appenders":["p2p"]}

# list of addresses, that will receive notification about in-chain events
# notifications-endpoint = 

# Whether to print backtrace on SIGSEGV
backtrace = yes

# Plugin(s) to enable, may be specified multiple times
plugin = node_status_api account_by_key account_by_key_api block_api condenser_api database_api json_rpc market_history market_history_api network_broadcast_api p2p rc_api state_snapshot transaction_status transaction_status_api wallet_bridge_api webserver

# The location of the rocksdb database for account history. By default it is $DATA_DIR/blockchain/account-history-rocksdb-storage
account-history-rocksdb-path = "blockchain/account-history-rocksdb-storage"

# Defines a range of accounts to track as a json pair ["from","to"] [from,to] Can be specified multiple times.
# account-history-rocksdb-track-account-range = 

# Defines a list of operations which will be explicitly logged.
# account-history-rocksdb-whitelist-ops = 

# Defines a list of operations which will be explicitly ignored.
# account-history-rocksdb-blacklist-ops = 

# Where to export data (NONE to discard)
block-data-export-file = NONE

# Skip producing when no factory is registered
block-data-skip-empty = 0

# How often to print out block_log_info (default 1 day)
block-log-info-print-interval-seconds = 86400

# Whether to defer printing until block is irreversible
block-log-info-print-irreversible = 1

# Where to print (filename or special sink ILOG, STDOUT, STDERR)
block-log-info-print-file = ILOG

# the location of the chain shared memory files (absolute path or relative to application data dir)
shared-file-dir = "blockchain"

# Size of the shared memory file. Default: 24G. If running with many plugins, increase this value to 28G.
shared-file-size = 24G

# A 2 precision percentage (0-10000) that defines the threshold for when to autoscale the shared memory file. Setting this to 0 disables autoscaling. Recommended value for consensus node is 9500 (95%).
shared-file-full-threshold = 0

# A 2 precision percentage (0-10000) that defines how quickly to scale the shared memory file. When autoscaling occurs the file's size will be increased by this percent. Setting this to 0 disables autoscaling. Recommended value is between 1000-2000 (10-20%)
shared-file-scale-rate = 0

# Pairs of [BLOCK_NUM,BLOCK_ID] that should be enforced as checkpoints.
# checkpoint = 

# flush shared memory changes to disk every N blocks
# flush-state-interval = 

# Compress blocks using zstd as they're added to the block log
enable-block-log-compression = 1

# If enabled, corrupted block_log will try to fix itself automatically.
enable-block-log-auto-fixing = 1

# Block log zstd compression level 0 (fast, low compression) - 22 (slow, high compression)
block-log-compression-level = 15

# Number of worker threads used to pre-validate transactions and blocks
blockchain-thread-pool-size = 8

# Level of detail of block stat reports: NONE, MINIMAL, REGULAR, FULL. Default FULL (recommended for API nodes).
block-stats-report-type = FULL

# Where to put block stat reports: DLOG, ILOG, NOTIFY, LOG_NOTIFY. Default ILOG.
block-stats-report-output = ILOG

# Level of detail of daily RC stat reports: NONE, MINIMAL, REGULAR, FULL. Default REGULAR.
rc-stats-report-type = REGULAR

# Where to put daily RC stat reports: DLOG, ILOG, NOTIFY, LOG_NOTIFY. Default ILOG.
rc-stats-report-output = ILOG

# Whether the block log should be single file (-1), not used at all & keeping only head block in memory (0), or split into files each containing 1M blocks & keeping N full million latest blocks (N). Default -1.
# Since CI performs both replay and sync of the node and since HAF opens the block lg in write mode after sync, this needs to be enabled to avoid block log access issues.
block-log-split = 9999

# WIF PRIVATE KEY to be used to sign each transaction.
# colony-sign-with = 

# Number of worker threads. Default is 4
colony-threads = 4

# Max number of transactions produced per block. When not set it will be sum of weights of individual types.
# colony-transactions-per-block = 

# Start producing transactions when block with given number becomes head block (or right at the start if the block already passed).
colony-start-at-block = 0

# Disables broadcasting of produced transactions - only local witness will include them in block.
colony-no-broadcast = 0

# Size and frequency parameters of article transactions.
# colony-article = 

# Size and frequency parameters of reply transactions.
# colony-reply = 

# Size and frequency parameters of vote transactions.
# colony-vote = 

# Size and frequency parameters of transfer transactions.
# colony-transfer = 

# Size and frequency parameters of custom_json transactions. If no other transaction type is requested, minimal custom jsons will be produced.
# colony-custom = 

# Starting block for comment cashout log
# cashout-logging-starting-block = 

# Ending block for comment cashout log
# cashout-logging-ending-block = 

# Path to log file
# cashout-logging-log-path-dir = 

# Database edits to apply on startup (may specify multiple times)
# debug-node-edit-script = 

# json-rpc log directory name.
# log-json-rpc = 

# Track market history by grouping orders into buckets of equal size measured in seconds specified as a JSON array of numbers
market-history-bucket-size = [15,60,300,3600,86400]

# How far back in time to track history for each bucket size, measured in the number of buckets (default: 5760)
market-history-buckets-per-size = 5760

# The local IP address and port to listen for incoming connections.
# p2p-endpoint = 

# Maxmimum number of incoming connections on P2P endpoint.
# p2p-max-connections = 

# The IP address and port of a remote peer to sync with.
p2p-seed-node = seed.hive.blog:2001 seed.openhive.network:2001 hive-seed.roelandp.nl:2001 hive-seed.arcange.eu:2001 anyx.io:2001 hived.splinterlands.com:2001 hive-api.3speak.tv:2001 node.mahdiyari.info:2001 hive-seed.lukestokes.info:2001 seed.deathwing.me:2001 hive-seed.actifit.io:2001 seed.shmoogleosukami.co.uk:2001 hiveseed.rishipanthee.com:2001 

# P2P network parameters. (Default: {"listen_endpoint":"0.0.0.0:0","accept_incoming_connections":true,"wait_if_endpoint_is_busy":true,"private_key":"0000000000000000000000000000000000000000000000000000000000000000","desired_number_of_connections":20,"maximum_number_of_connections":200,"peer_connection_retry_timeout":30,"peer_inactivity_timeout":5,"peer_advertising_disabled":false,"maximum_number_of_blocks_to_handle_at_one_time":200,"maximum_number_of_sync_blocks_to_prefetch":20000,"maximum_blocks_per_peer_during_syncing":200,"active_ignored_request_timeout_microseconds":6000000} )
# p2p-parameters = 

# path to block_log file - source of block emissions
# pacemaker-source = 

# minimum time of emission offset from block timestamp in milliseconds, default -300ms
pacemaker-min-offset = -300

# maximum time of emission offset from block timestamp in milliseconds, default 20000ms (when exceeded, node will be stopped)
pacemaker-max-offset = 20000

# postgres connection string
# psql-url = 

# indexes/constraints will be recreated if `psql_block_number + psql_index_threshold >= head_block_number`
psql-index-threshold = 20000000

# number of threads which dump operations to database during reindexing
psql-operations-threads-number = 5

# number of threads which dump transactions to database during reindexing
psql-transactions-threads-number = 2

# number of threads which dump account operations to database during reindexing
psql-account-operations-threads-number = 2

# enable collect data to account_operations table
psql-enable-account-operations-dump = 1

# force open database even when irreversible data are inconsistent
psql-force-open-inconsistent = false

# threshold to move synchronization state during start immediatly to live
psql-livesync-threshold = 0

# Defines a range of accounts to track as a json pair ["from","to"] [from,to]. Can be specified multiple times.
# psql-track-account-range = 

# Defines operations' types to track. Can be specified multiple times.
# psql-track-operations = 

# For a type of operation it's defined a regex that filters body of operation and decides if it's excluded. Can be specified multiple times. A complex regex can cause slowdown or processing can be even abandoned due to complexity.
# psql-track-body-operations = 

# enable filtering accounts and operations
psql-enable-filter = 1

# first synced block
psql-first-block = 1

# write-ahead log for data sent from hived to PostgreSQL
# psql-wal-directory = 

# The location (root-dir) of the snapshot storage, to save/read portable state dumps
snapshot-root-dir = "snapshot"

# Endpoint to send statsd messages to.
# statsd-endpoint = 

# Size to batch statsd messages.
statsd-batchsize = 1

# Whitelist of statistics to capture.
# statsd-whitelist = 

# Blacklist of statistics to capture.
# statsd-blacklist = 

# Defines the number of blocks from the head block that transaction statuses will be tracked.
transaction-status-block-depth = 64000

# Local http endpoint for webserver requests.
# webserver-http-endpoint = 

# Local https endpoint for webserver requests.
# webserver-https-endpoint = 

# Local unix http endpoint for webserver requests.
# webserver-unix-endpoint = 

# Local websocket endpoint for webserver requests.
# webserver-ws-endpoint = 

# Enable the RFC-7692 permessage-deflate extension for the WebSocket server (only used if the client requests it).  This may save bandwidth at the expense of CPU
webserver-ws-deflate = 0

# Number of threads used to handle queries. Default: 32.
webserver-thread-pool-size = 32

# File name with a server's certificate.
# webserver-https-certificate-file-name = 

# File name with a server's private key.
# webserver-https-key-file-name = 

# Enable block production, even if the chain is stale.
enable-stale-production = 0

# Percent of witnesses (0-99) that must be participating in order to produce blocks
required-participation = 33

# name of witness controlled by this node (e.g. initwitness )
# witness = 

# WIF PRIVATE KEY to be used by one or more witnesses or miners
# private-key = 

